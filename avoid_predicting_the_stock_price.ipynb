{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2833ba5c",
   "metadata": {},
   "source": [
    "# Avoid Predicting the Stock Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe5a42",
   "metadata": {},
   "source": [
    "Data Sources:\n",
    "Yahoo Finance through yfinance\n",
    "Ticker selected = \\[MSFT, GOOGL, NVDA, AAPL, AMZN, TSLA, FB(META)\\]\n",
    "\n",
    "Implemented:\n",
    "\n",
    "1. Chart with technical indicator.\n",
    "1. Fourier transform decomposition.\n",
    "1. Forecasting with ARIMA, Prophet.\n",
    "1. Time series GAN\n",
    "\n",
    "[Dependencies](#dpdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83473e65",
   "metadata": {
    "id": "4caa87f8"
   },
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8c7fe",
   "metadata": {
    "id": "4f2b96eb"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmdarima as pm\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yfinance as yf\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from sklearn import ensemble, model_selection, preprocessing\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_style = {\n",
    "    'figure.autolayout': True,  # Figure automatically adjust layout\n",
    "    'figure.titlesize': 20,  # Figure suptitle font size\n",
    "    'figure.figsize': (10, 5),  # Figure figsize\n",
    "    'figure.dpi': 100,  # Figure dots per inch\n",
    "    'axes.spines.top': False,  # Draw Axis spines top\n",
    "    'axes.spines.left': False,  # Draw Axis spin left\n",
    "    'axes.titlesize': 10,  # Axes title font size\n",
    "    'axes.titlelocation': 'left',  # Axes title alignment\n",
    "    'axes.labelsize': 14,  # Axes label size\n",
    "    'axes.grid': True,  # Axes grid\n",
    "    'grid.color': '#969696',  # Axes grid col\n",
    "    'xtick.direction': 'inout',  # Xtick direction\n",
    "    'ytick.direction': 'inout',  # Ytick direction\n",
    "    'xtick.minor.visible': True,  # Draw Xtick minor\n",
    "    'ytick.minor.visible': True,  # Draw Ytick minor\n",
    "    'ytick.right': True,  # Draw ticks right\n",
    "    'ytick.left': False,  # Draw ticks left\n",
    "    'ytick.labelright': True,  # Draw ticks label right\n",
    "    'ytick.labelleft': False,  # Draw ticks label left\n",
    "    'xaxis.labellocation': 'right',  # Xaxis alignment\n",
    "    'yaxis.labellocation': 'top',  # Yaxis alignment\n",
    "    'font.family': 'serif',  # Figure font\n",
    "    'legend.fontsize': 10,  # Legend font size\n",
    "    'legend.loc': 'best',  # Legend location\n",
    "}\n",
    "\n",
    "# print('========================================')\n",
    "# print('Auto Configured:')\n",
    "# print('========================================')\n",
    "# for k, v in zip(list(custom_style.keys()), list(custom_style.values())):\n",
    "#     n = 30 - len(k)\n",
    "#     print(str(k) + str(' '*n) + str(v))\n",
    "# print('========================================')\n",
    "# print('Further Configure: ')\n",
    "# print('========================================')\n",
    "# print('ax.yaxis.set_label_position('right')')\n",
    "# print('mpl.rcParams.update(mpl.rcParamsDefault)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %config InlineBackend.figure_format='svg'\n",
    "plt.style.use(custom_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8b4d7",
   "metadata": {
    "id": "d92b9e2c"
   },
   "source": [
    "### Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aac395",
   "metadata": {
    "id": "73f1f907"
   },
   "outputs": [],
   "source": [
    "ticker_strings = ['MSFT', 'AAPL', 'GOOGL', 'FB', 'NVDA', 'TSLA', 'AMZN']\n",
    "\n",
    "temp_df = list()\n",
    "for ticker in ticker_strings:\n",
    "    data = yf.download(ticker, group_by='Ticker', start='2000-07-07', end='2021-07-08')\n",
    "    data['Ticker'] = ticker\n",
    "    temp_df.append(data)\n",
    "\n",
    "data = pd.concat(temp_df)\n",
    "assert type(data.index) == pd.core.indexes.datetimes.DatetimeIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb33097",
   "metadata": {
    "id": "0debaca5"
   },
   "source": [
    "### Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f510ad0",
   "metadata": {
    "id": "26dd041e"
   },
   "outputs": [],
   "source": [
    "def ticker_separation(data):\n",
    "    msft = data[data['Ticker'] == 'MSFT'].drop(columns='Ticker')\n",
    "    aapl = data[data['Ticker'] == 'AAPL'].drop(columns='Ticker')\n",
    "    googl = data[data['Ticker'] == 'GOOGL'].drop(columns='Ticker')\n",
    "    fb = data[data['Ticker'] == 'FB'].drop(columns='Ticker')\n",
    "    nvda = data[data['Ticker'] == 'NVDA'].drop(columns='Ticker')\n",
    "    tsla = data[data['Ticker'] == 'TSLA'].drop(columns='Ticker')\n",
    "    amzn = data[data['Ticker'] == 'AMZN'].drop(columns='Ticker')\n",
    "\n",
    "    ticker_dict = {\n",
    "        'MSFT': msft,\n",
    "        'AAPL': aapl,\n",
    "        'GOOGL': googl,\n",
    "        'FB': fb,\n",
    "        'NVDA': nvda,\n",
    "        'TSLA': tsla,\n",
    "        'AMZN': amzn,\n",
    "    }\n",
    "\n",
    "    return ticker_dict\n",
    "\n",
    "\n",
    "ticker_dict = ticker_separation(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b267a",
   "metadata": {
    "id": "332f0a25"
   },
   "source": [
    "### History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ccc95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "executionInfo": {
     "elapsed": 1832,
     "status": "ok",
     "timestamp": 1640179744847,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "118ce797",
    "outputId": "5ad839f2-367a-4f07-d8eb-118758da86f1"
   },
   "outputs": [],
   "source": [
    "def history_performance(df):\n",
    "    scaled_df = list()\n",
    "    floating = df.select_dtypes(\n",
    "        include=['float64']\n",
    "    ).columns.values  # Select columns with floating data type\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    for t in df['Ticker'].unique():\n",
    "        temp = df[df['Ticker'] == t].copy()\n",
    "        temp[floating] = scaler.fit_transform(temp[floating])\n",
    "        scaled_df.append(temp)\n",
    "\n",
    "    scaled_df = pd.concat(scaled_df)\n",
    "\n",
    "    color_list = [\n",
    "        '#00a4ef',\n",
    "        '#a2aaad',\n",
    "        '#fbbc05',\n",
    "        '#4267b2',\n",
    "        '#76b900',\n",
    "        '#e82127',\n",
    "        '#ff9900',\n",
    "        '#00a270',\n",
    "    ]\n",
    "    fig, ax = plt.subplots(dpi=200)\n",
    "    for t, c in zip(scaled_df['Ticker'].unique(), color_list):\n",
    "        plt.plot(\n",
    "            scaled_df[scaled_df['Ticker'] == t].index,\n",
    "            scaled_df[scaled_df['Ticker'] == t]['Close'],\n",
    "            c=c,\n",
    "            label=t,\n",
    "        )\n",
    "    plt.suptitle('History', ha='left', x=0.015, y=1)\n",
    "    plt.title('Established')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Scaled Values')\n",
    "    plt.xlabel('Date')\n",
    "    ax.yaxis.set_label_position('right')\n",
    "    plt.savefig(\"fig/history_performance.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "history_performance(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b10ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8938,
     "status": "ok",
     "timestamp": 1640179756707,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "cf2b2615",
    "outputId": "77f7430f-3992-4667-a577-9de135f02528"
   },
   "outputs": [],
   "source": [
    "def plot_ohlc(df, ticker):\n",
    "    df = df[df['Ticker'] == ticker].tail(30).reset_index()\n",
    "    x = np.arange(0, len(df))\n",
    "    fig, (ax, ax2) = plt.subplots(\n",
    "        2, figsize=(10, 5), gridspec_kw={'height_ratios': [4, 1]}, dpi=100\n",
    "    )\n",
    "    for idx, value in df.iterrows():\n",
    "        color = '#2CA453'\n",
    "        if value['Open'] > value['Close']:\n",
    "            color = '#F04730'\n",
    "        ax.plot([x[idx], x[idx]], [value['Low'], value['High']], color=color)\n",
    "        ax.plot([x[idx], x[idx] - 0.1], [value['Open'], value['Open']], color=color)\n",
    "        ax.plot([x[idx], x[idx] + 0.1], [value['Close'], value['Close']], color=color)\n",
    "\n",
    "    ax2.bar(x, df['Volume'], color='lightgrey')\n",
    "    max_ = df['Volume'].max() * 1.1\n",
    "    yticks_ax2 = np.arange(0, max_ + 1, max_ / 4)\n",
    "    yticks_labels_ax2 = ['{:.2f} M'.format(i / 1000000) for i in yticks_ax2]\n",
    "    plt.yticks(yticks_ax2[1:-1], yticks_labels_ax2[1:-1])\n",
    "    plt.ylim(0, max_)\n",
    "\n",
    "    ax.set_xticks(x, minor=True)\n",
    "    ax.set_ylabel('Price')\n",
    "    ax2.set_xticks(x[::3])\n",
    "    ax2.set_xticklabels(df.Date.dt.date[::3])\n",
    "    ax2.set_ylabel('Volume')\n",
    "    ax2.yaxis.tick_right()\n",
    "\n",
    "    ax.grid(axis='y')\n",
    "    ax2.grid(False)\n",
    "\n",
    "    plt.suptitle('Candlestick: {}'.format(ticker), ha='left', x=0.015, y=1)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "\n",
    "def plot_candlestick(df, ticker):\n",
    "    df = df[df['Ticker'] == t].tail(180)\n",
    "    mpf.plot(\n",
    "        df,\n",
    "        figratio=(10, 5),\n",
    "        type='candle',\n",
    "        mav=(7, 21),\n",
    "        volume=True,\n",
    "        title=ticker,\n",
    "        style='classic',\n",
    "    )\n",
    "\n",
    "\n",
    "# for t in data['Ticker'].unique():\n",
    "# plot_ohlc(data, ticker=t)\n",
    "# plot_candlestick(data, ticker=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296921c4",
   "metadata": {
    "id": "489160b0"
   },
   "outputs": [],
   "source": [
    "# mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "# plt.style.use(custom_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96ddbe",
   "metadata": {
    "id": "0463a0f8"
   },
   "source": [
    "### Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fd3635",
   "metadata": {
    "id": "23a520b8"
   },
   "outputs": [],
   "source": [
    "def some_indicators(df, o, c, h, l, v):\n",
    "    result = list()\n",
    "    for t in df['Ticker'].unique():\n",
    "        temp = df[df['Ticker'] == t].copy()\n",
    "\n",
    "        # Trend\n",
    "\n",
    "        # Simple Moving Average\n",
    "        temp['SMA20'] = temp[c].rolling(window=20).mean()\n",
    "        temp['SMA50'] = temp[c].rolling(window=50).mean()\n",
    "        temp['SMA150'] = temp[c].rolling(window=150).mean()\n",
    "        temp['SMA200'] = temp[c].rolling(window=200).mean()\n",
    "\n",
    "        # Exponential Moving Average\n",
    "        temp['EMA20'] = temp[c].ewm(span=20).mean()\n",
    "        temp['EMA40'] = temp[c].ewm(span=40).mean()\n",
    "\n",
    "        # Weighted Moving Average\n",
    "        weights = np.array([0.4, 0.2, 0.2, 0.1, 0.1])\n",
    "        sum_weights = np.sum(weights)\n",
    "        temp['WMA5'] = (\n",
    "            temp[c]\n",
    "            .rolling(window=5)\n",
    "            .apply(lambda x: np.sum(weights * x) / sum_weights, raw=False)\n",
    "        )\n",
    "\n",
    "        # Moving Average Convergence Divergence\n",
    "        temp['EMA26'] = temp[[c]].ewm(span=26).mean()\n",
    "        temp['EMA12'] = temp[[c]].ewm(span=12).mean()\n",
    "        temp['MACD'] = temp['EMA12'] - temp['EMA26']\n",
    "\n",
    "        # Volatility\n",
    "\n",
    "        # Bollinger Band\n",
    "        temp['20SD'] = temp[c].rolling(window=20).std()\n",
    "        temp['UB'] = temp['SMA20'] + (temp['20SD'] * 2)\n",
    "        temp['LB'] = temp['SMA20'] - (temp['20SD'] * 2)\n",
    "\n",
    "        # Average True Range\n",
    "        atr_window = 14\n",
    "        Previous_close = temp[c].shift(1)\n",
    "        true_range = pd.DataFrame(\n",
    "            data={\n",
    "                'tr1': temp[h] - temp[l],\n",
    "                'tr2': (temp[h] - Previous_close).abs(),\n",
    "                'tr3': (temp[l] - Previous_close).abs(),\n",
    "            }\n",
    "        ).max(axis=1)\n",
    "        ATR = np.zeros(len(temp[c]))\n",
    "        ATR[atr_window - 1] = true_range[0:atr_window].mean()\n",
    "        for i in range(atr_window, len(ATR)):\n",
    "            ATR[i] = (ATR[i - 1] * (atr_window - 1) + true_range.iloc[i]) / float(\n",
    "                atr_window\n",
    "            )\n",
    "        ATR = pd.Series(data=ATR, index=true_range.index)\n",
    "        temp.insert(temp.shape[1], 'ATR', ATR)\n",
    "\n",
    "        # Momentum\n",
    "\n",
    "        # Stochastic Oscillator\n",
    "        stoch_window = 14\n",
    "        stoch_smooth_window = 3\n",
    "        stoch_periods = 14\n",
    "        S_min = temp[l].rolling(stoch_window, min_periods=stoch_periods).min()\n",
    "        S_max = temp[h].rolling(stoch_window, min_periods=stoch_periods).max()\n",
    "        STOCH = 100 * (temp[c] - S_min) / (S_max - S_min)\n",
    "        temp.insert(temp.shape[1], 'STOCH', STOCH)\n",
    "\n",
    "        # Relative Strength Index\n",
    "        rsi_periods = 14\n",
    "        diff = temp[c].diff(1)\n",
    "        UP_direction = diff.where(diff > 0, 0.0)\n",
    "        DOWN_direction = -diff.where(diff < 0, 0.0)\n",
    "        EMA_up = UP_direction.ewm(\n",
    "            alpha=1 / rsi_periods, min_periods=rsi_periods, adjust=rsi_periods\n",
    "        ).mean()\n",
    "        EMA_down = DOWN_direction.ewm(\n",
    "            alpha=1 / rsi_periods, min_periods=rsi_periods, adjust=rsi_periods\n",
    "        ).mean()\n",
    "        RSI = pd.Series(\n",
    "            np.where(EMA_down == 0, 100, 100 - (100 / (1 + (EMA_up / EMA_down)))),\n",
    "            index=temp[c].index,\n",
    "        )\n",
    "        temp.insert(temp.shape[1], 'RSI', RSI)\n",
    "\n",
    "        # Volume\n",
    "\n",
    "        # Accumulation/Distribution Index\n",
    "        CLV = (\n",
    "            ((temp[c] - temp[l]) - (temp[h] - temp[c])) / (temp[h] - temp[l])\n",
    "        ).fillna(0.0)\n",
    "        ADI = CLV * temp[v]\n",
    "        temp['ADI'] = ADI.cumsum()\n",
    "\n",
    "        # On-Balance Volume\n",
    "        OBV = np.where(temp[c] < temp[c].shift(1), -temp[v], temp[v])\n",
    "        OBV = pd.Series(OBV, index=temp[c].index).cumsum()\n",
    "        temp.insert(temp.shape[1], 'OBV', OBV)\n",
    "\n",
    "        result.append(temp)\n",
    "\n",
    "    result = pd.concat(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "data = some_indicators(df=data, o='Open', c='Close', h='High', l='Low', v='Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9a824",
   "metadata": {
    "id": "de7193dc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def technical_chart(ticker_name, ticker_df, last_n, plot=True):\n",
    "    assert type(ticker_name) == str\n",
    "\n",
    "    if plot:\n",
    "        ticker_df = ticker_df.tail(last_n)\n",
    "        fig, ax = plt.subplots(figsize=(10, 5), dpi=200)\n",
    "        ax.plot(ticker_df.index, ticker_df['Close'], c='black', label='Close')\n",
    "        ax.plot(ticker_df.index, ticker_df['SMA50'], c='b', label='SMA50')\n",
    "        ax.plot(ticker_df.index, ticker_df['SMA150'], c='g', label='SMA150')\n",
    "        ax.plot(ticker_df.index, ticker_df['SMA200'], c='r', label='SMA200')\n",
    "        ax.fill_between(\n",
    "            ticker_df.index,\n",
    "            ticker_df['LB'],\n",
    "            ticker_df['UB'],\n",
    "            alpha=0.35,\n",
    "            label='Bollinger Band',\n",
    "        )\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "        zoom_df = ticker_df.tail(last_n - math.ceil(last_n * 0.9))\n",
    "        ax2 = fig.add_axes([0.01, 0.55, 0.25, 0.30])  # left, bottom, width, height\n",
    "        ax2.plot(zoom_df.index, zoom_df['Close'], label='Close')\n",
    "        ax2.plot(zoom_df.index, zoom_df['EMA20'], label='EMA20')\n",
    "        ax2.plot(zoom_df.index, zoom_df['EMA40'], label='EMA40')\n",
    "        ax2.legend(prop={'size': 5})\n",
    "        ax2.xaxis.set_major_locator(mdates.MonthLocator(interval=12))\n",
    "\n",
    "        plt.suptitle('{}'.format(ticker_name), ha='left', x=0.015, y=1)\n",
    "        plt.title('Short Term Performance')\n",
    "        plt.savefig(\"fig/technical_chart_{}.png\".format(ticker_name))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for t in data['Ticker'].unique():\n",
    "    technical_chart(t, data[data['Ticker'] == t], last_n=999, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d125d",
   "metadata": {
    "id": "693ab6e6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def technical_chart2(ticker_name, ticker_df, last_n, plot=True):\n",
    "    assert type(ticker_name) == str\n",
    "\n",
    "    if plot:\n",
    "        ticker_df = ticker_df.tail(last_n)\n",
    "        fig, axs = plt.subplots(3, 2, figsize=(10, 7), dpi=200)\n",
    "        axs[0, 0].plot(ticker_df.index, ticker_df['MACD'])\n",
    "        axs[0, 0].set_title('Moving Average Convergence Divergence')\n",
    "        axs[0, 1].plot(ticker_df.index, ticker_df['ATR'])\n",
    "        axs[0, 1].set_title('Average True Range')\n",
    "        axs[1, 0].plot(ticker_df.index, ticker_df['STOCH'])\n",
    "        axs[1, 0].set_title('Stochastic Oscillator')\n",
    "        axs[1, 1].plot(ticker_df.index, ticker_df['RSI'])\n",
    "        axs[1, 1].set_title('Relative Strength Index')\n",
    "        axs[2, 0].plot(ticker_df.index, ticker_df['ADI'])\n",
    "        axs[2, 0].set_title('Accumulation/Distribution Index')\n",
    "        axs[2, 1].plot(ticker_df.index, ticker_df['OBV'])\n",
    "        axs[2, 1].set_title('On-Balance Volume')\n",
    "        plt.suptitle(\n",
    "            'Technical Indicator: {}'.format(ticker_name), ha='left', x=0.015, y=1\n",
    "        )\n",
    "        plt.savefig(\"fig/technical_indicator_{}.png\".format(ticker_name))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for t in data['Ticker'].unique():\n",
    "    technical_chart2(t, data[data['Ticker'] == str(t)], last_n=100, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc59655",
   "metadata": {
    "id": "6a62a41a"
   },
   "source": [
    "### Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb293d93",
   "metadata": {
    "id": "5a0eb444",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fourier_transformation(df, tn, plot=True):\n",
    "    assert type(tn) == str\n",
    "\n",
    "    fft_df = pd.DataFrame({'fft': np.fft.fft(np.asarray(df['Close']))})\n",
    "    fft_df['Absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))\n",
    "    fft_df['Angle'] = fft_df['fft'].apply(lambda x: np.angle(x))\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5), dpi=200)\n",
    "        fftlist = np.asarray(fft_df['fft'])\n",
    "        for n in [3, 6, 9, 78]:\n",
    "            fftlistc = np.copy(fftlist)\n",
    "            fftlistc[n:-n] = 0\n",
    "            ax.plot(np.fft.ifft(fftlistc), label='FT Component {}'.format(n))\n",
    "        ax.plot(df['Close'], label='Close')\n",
    "        ax.yaxis.set_label_position('right')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Close')\n",
    "        plt.suptitle('Fourier Tranform: {}'.format(tn), ha='left', x=0.015, y=1)\n",
    "        plt.savefig(\"fig/fourier_transform_{}.png\".format(tn))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for tn, tdf in zip(list(ticker_dict.keys()), list(ticker_dict.values())):\n",
    "    fourier_transformation(df=tdf.reset_index()[['Date', 'Close']], tn=tn, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d978f2",
   "metadata": {
    "id": "29ce03a9"
   },
   "source": [
    "### Hyperparameter Tuning for ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28835b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403424,
     "status": "ok",
     "timestamp": 1640180258316,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "3fb13ec8",
    "outputId": "901974ff-f8e6-49ae-efdc-fcf5920a3677"
   },
   "outputs": [],
   "source": [
    "def optimal_arima(df, tn, cn):\n",
    "    assert type(tn) == str\n",
    "\n",
    "    print('Ticker: {}'.format(tn))\n",
    "    oarima_model = pm.auto_arima(\n",
    "        df[cn],\n",
    "        start_p=1,\n",
    "        start_q=1,\n",
    "        test='adf',\n",
    "        max_p=5,\n",
    "        max_q=5,\n",
    "        max_d=5,\n",
    "        seasonal=False,\n",
    "        trace=True,\n",
    "        random_state=7,\n",
    "    )\n",
    "    # print('')\n",
    "    # display(oarima_model.summary())\n",
    "    return oarima_model.order\n",
    "\n",
    "\n",
    "arima_params = dict()\n",
    "for tn, tdf in zip(list(ticker_dict.keys()), list(ticker_dict.values())):\n",
    "    tdf = tdf.dropna(subset=['Close'])\n",
    "    # optimal_arima(df=tdf, tn=tn, cn='Close')\n",
    "    arima_params[tn] = optimal_arima(df=tdf, tn=tn, cn='Close')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89948221",
   "metadata": {
    "id": "6fedde66"
   },
   "source": [
    "### ARIMA Model Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1e0bf",
   "metadata": {
    "id": "bf69e5eb"
   },
   "outputs": [],
   "source": [
    "def arima_model(df, tn, cn, params, n_days, forecast_days, plot=True):\n",
    "    assert type(tn) == str\n",
    "    assert type(cn) == str\n",
    "\n",
    "    if n_days > len(df):\n",
    "        raise Exception('n_days > length of data')\n",
    "    else:\n",
    "        warnings.filterwarnings('ignore')\n",
    "        start = time.time()\n",
    "        recent = df.tail(n_days).copy()\n",
    "        series = recent[cn]\n",
    "        arima = ARIMA(series, order=params)\n",
    "        arima_fitted = arima.fit(disp=0)\n",
    "        # print(arima_fitted.summary())\n",
    "        # autocorrelation_plot(series)\n",
    "        X = series.values\n",
    "        split = int(len(X) * 0.70)\n",
    "        train, test = X[0:split], X[split : len(X)]\n",
    "        history = [x for x in train]\n",
    "        predictions = list()\n",
    "        for t in range(len(test)):\n",
    "            arima = ARIMA(history, order=(5, 1, 0))\n",
    "            arima_fitted = arima.fit(disp=0)\n",
    "            predictions.append(arima_fitted.forecast()[0])\n",
    "            obs = test[t]\n",
    "            history.append(obs)\n",
    "\n",
    "        error = np.round(np.mean((test - predictions) ** 2), 4)\n",
    "\n",
    "        forecast, se, ci = arima_fitted.forecast(forecast_days, alpha=0.05)\n",
    "        forecast_date = pd.date_range(recent.index[-1], periods=forecast_days).tolist()\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(figsize=(10, 5), dpi=200)\n",
    "            ax.plot(recent.index[: len(train)], train, label='Training')\n",
    "            ax.plot(recent.index[-len(test) :], test, label='Testing')\n",
    "            ax.plot(\n",
    "                recent.index[-len(test) :], predictions, color='r', label='Predicted'\n",
    "            )\n",
    "            ax.plot(forecast_date, forecast, c='black', label='Forecast')\n",
    "            ax.fill_between(forecast_date, ci[:, 0], ci[:, 1], alpha=0.35)\n",
    "            ax.yaxis.set_label_position('right')\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.xlabel('Days')\n",
    "            plt.ylabel(cn)\n",
    "            plt.suptitle('ARIMA Model: {}'.format(tn), ha='left', x=0.015, y=1)\n",
    "            plt.title(\n",
    "                'MSE: {} | Run Time: {} | Params(p,q,d): {} | Forecast days: {}'.format(\n",
    "                    error, round(end - start, 6), params, forecast_days\n",
    "                ),\n",
    "                c='grey',\n",
    "            )\n",
    "            plt.savefig(\"fig/arima_forecast_{}.png\".format(tn))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "for tn, tdf, params in zip(\n",
    "    list(ticker_dict.keys()), list(ticker_dict.values()), list(arima_params.values())\n",
    "):\n",
    "    arima_model(\n",
    "        df=tdf,\n",
    "        tn=tn,\n",
    "        cn='Close',\n",
    "        params=params,\n",
    "        n_days=200,\n",
    "        forecast_days=30,\n",
    "        plot=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dbeb3d",
   "metadata": {
    "id": "b99087d6"
   },
   "source": [
    "### Prophet Model Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216a1b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63198,
     "status": "ok",
     "timestamp": 1640180363090,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "47d89e63",
    "outputId": "6c07f7b3-50ea-46ee-8c63-8ea8fdd987e8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prophet_model(df, tn, cn, n_days, forecast_days, plot=True):\n",
    "    assert type(tn) == str\n",
    "    assert type(cn) == str\n",
    "\n",
    "    short = df.tail(n_days).copy()\n",
    "\n",
    "    # param_grid = {\n",
    "    #     'changepoint_prior_scale': [0.001, 0.01, 0.1],\n",
    "    #     'seasonality_prior_scale': [0.01, 0.1, 1.0]}\n",
    "    # all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    # errors = list()\n",
    "    # cutoffs = pd.to_datetime(['2018-07-08', '2019-01-01', '2019-07-08'])\n",
    "\n",
    "    # for params in all_params:\n",
    "    #      fbp = Prophet(**params, daily_seasonality=True)\\\n",
    "    #     .fit(short.reset_index().rename(columns={'Date': 'ds', cn: 'y'})[['ds', 'y']])\n",
    "    #     cv = cross_validation(fbp, cutoffs=cutoffs, horizon='365 days')\n",
    "    #     pm = performance_metrics(cv, rolling_window=1)\n",
    "    #     errors.append(pm['rmse'].values[0])\n",
    "\n",
    "    # tuning_results = pd.DataFrame(all_params)\n",
    "    # tuning_results['rmse'] = errors\n",
    "    # display(tuning_results)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    fbp = Prophet(\n",
    "        changepoint_prior_scale=0.001,\n",
    "        seasonality_prior_scale=0.01,\n",
    "        daily_seasonality=True,\n",
    "    )\n",
    "    fbp.fit(short.reset_index().rename(columns={'Date': 'ds', cn: 'y'})[['ds', 'y']])\n",
    "    future = fbp.make_future_dataframe(periods=forecast_days)\n",
    "    forecast = fbp.predict(future)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(dpi=200)\n",
    "        ax.plot(\n",
    "            forecast['ds'][:-forecast_days],\n",
    "            forecast['yhat'][:-forecast_days],\n",
    "            label='Training',\n",
    "            c='black',\n",
    "        )\n",
    "        ax.plot(\n",
    "            forecast['ds'][-forecast_days:],\n",
    "            forecast['yhat'][-forecast_days:],\n",
    "            label='Forecast',\n",
    "            c='#0072b2',\n",
    "        )\n",
    "        ax.fill_between(\n",
    "            forecast['ds'][-forecast_days:],\n",
    "            forecast['yhat_lower'][-forecast_days:],\n",
    "            forecast['yhat_upper'][-forecast_days:],\n",
    "            label='CI',\n",
    "            color='#bedaea',\n",
    "        )\n",
    "        ax.yaxis.set_label_position('right')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(cn)\n",
    "        plt.legend()\n",
    "        plt.suptitle('Prophet: {}'.format(tn), ha='left', x=0.015, y=1)\n",
    "        plt.title(\n",
    "            'Commence: {} | End: {} | Run Time: {} | Forecast days: {}'.format(\n",
    "                str(short.index.min())[:10],\n",
    "                str(short.index.max())[:10],\n",
    "                round(end - start, 6),\n",
    "                forecast_days,\n",
    "            ),\n",
    "            c='grey',\n",
    "        )\n",
    "        plt.savefig(\"fig/prophet_forecast_{}.png\".format(tn))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for tn, tdf in zip(list(ticker_dict.keys()), list(ticker_dict.values())):\n",
    "    prophet_model(df=tdf, tn=tn, cn='Close', n_days=1000, forecast_days=300, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba928d32",
   "metadata": {
    "id": "0cdec542"
   },
   "source": [
    "### Time Series Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b0a33",
   "metadata": {
    "id": "7f6925e2"
   },
   "outputs": [],
   "source": [
    "filtered = data.loc['2018-07-07':]\n",
    "filtered_ticker_dict = dict(tuple(filtered.groupby('Ticker')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9cd31b",
   "metadata": {
    "id": "101b7ecb"
   },
   "outputs": [],
   "source": [
    "r = pd.DataFrame()\n",
    "for tn, tdf in zip(\n",
    "    list(filtered_ticker_dict.keys()), list(filtered_ticker_dict.values())\n",
    "):\n",
    "    r = r.add(tdf.iloc[:, 0:6], fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09382b",
   "metadata": {
    "id": "c4c2a7b2"
   },
   "outputs": [],
   "source": [
    "ngpu = torch.cuda.device_count()\n",
    "for i in range(ngpu):\n",
    "    print('GPU {}: {}'.format(i + 1, torch.cuda.get_device_name(i)))\n",
    "\n",
    "device = torch.device('cuda:0' if (torch.cuda.is_available() and ngpu > 0) else 'cpu')\n",
    "num_epochs = 100000\n",
    "evaluation_epoch_num = 10000\n",
    "batch_size = 64\n",
    "optimizer_betas = (0.9, 0.999)\n",
    "learning_rate = 5.125e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74592d8f",
   "metadata": {
    "id": "131f4ac9"
   },
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):\n",
    "    def __init__(self, data_frame, sequence_length=2):\n",
    "        self.data = torch.tensor(data_frame.values)\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index : index + self.sequence_length].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b9ac7",
   "metadata": {
    "id": "41eb0808"
   },
   "outputs": [],
   "source": [
    "training_columns_list = ['Close', 'Open', 'High', 'Low']\n",
    "data_dimension = len(training_columns_list)\n",
    "sequence_length = 7\n",
    "\n",
    "train_data, evaluation_data = model_selection.train_test_split(\n",
    "    r[training_columns_list], test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data[train_data.columns] = scaler.transform(train_data)\n",
    "evaluation_data[evaluation_data.columns] = scaler.transform(evaluation_data)\n",
    "\n",
    "validation_data, test_data = model_selection.train_test_split(\n",
    "    evaluation_data, test_size=0.5, shuffle=False\n",
    ")\n",
    "\n",
    "train_dataset = TimeseriesDataset(train_data, sequence_length)\n",
    "test_dataset = TimeseriesDataset(test_data, sequence_length)\n",
    "validation_dataset = TimeseriesDataset(validation_data, sequence_length)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    validation_dataset, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afb9bb",
   "metadata": {
    "id": "2d8fd0ac"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=data_dimension,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            dropout=0.2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.linear = nn.Linear(hidden_size, data_dimension)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, input_sequences):\n",
    "        input_sequences = self.drop(input_sequences)\n",
    "        lstm_output, hidden_cell = self.lstm(input_sequences)\n",
    "        res = self.linear(hidden_cell[0][-1])\n",
    "        res = res.view(res.shape[0], 1, -1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df53e20b",
   "metadata": {
    "id": "46ef783f"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=data_dimension,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            dropout=0.2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.linear = nn.Sequential(nn.Linear(hidden_size, 1), nn.Sigmoid())\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, input_sequences):\n",
    "        input_sequences = self.drop(input_sequences)\n",
    "        lstm_output, hidden_cell = self.lstm(input_sequences)\n",
    "        res = self.linear(hidden_cell[0][-1])\n",
    "        res = res.view(res.shape[0], 1, -1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff095c52",
   "metadata": {
    "id": "b3c12fa0"
   },
   "outputs": [],
   "source": [
    "def model_rmse(\n",
    "    model,\n",
    "    dataloader,\n",
    "    epoch,\n",
    "    plot_graph=True,\n",
    "    plot_title='TSGAN Prediction',\n",
    "    show_preds=True,\n",
    "):\n",
    "    rmse = 0\n",
    "    squared_error_list = []\n",
    "    actual_data_list = []\n",
    "    predicted_data_list = []\n",
    "    file_title = plot_title.lower().replace(' ', '_')\n",
    "\n",
    "    for i, sequence_batch in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            real_sequence = sequence_batch\n",
    "            generator_input_sequence = sequence_batch[:, :-1].to(device)\n",
    "            real_values = sequence_batch[:, -1:]\n",
    "            predicted_values = generator(generator_input_sequence).cpu()\n",
    "            actual_data_list.append(real_values)\n",
    "            predicted_data_list.append(predicted_values)\n",
    "\n",
    "    real_data = torch.cat(actual_data_list, 0)\n",
    "    predicted_data = torch.cat(predicted_data_list, 0)\n",
    "\n",
    "    df_pred = pd.DataFrame(\n",
    "        predicted_data.view(-1, len(training_columns_list)),\n",
    "        columns=training_columns_list,\n",
    "    )\n",
    "    df_pred_unscaled = pd.DataFrame(\n",
    "        scaler.inverse_transform(df_pred), columns=training_columns_list\n",
    "    )\n",
    "    df_real = pd.DataFrame(\n",
    "        real_data.view(-1, len(training_columns_list)), columns=training_columns_list\n",
    "    )\n",
    "    df_real_unscaled = pd.DataFrame(\n",
    "        scaler.inverse_transform(df_real), columns=training_columns_list\n",
    "    )\n",
    "\n",
    "    if plot_graph:\n",
    "        if not os.path.exists('./fig/plots_gan/'):\n",
    "            os.makedirs('./fig/plots_gan/')\n",
    "\n",
    "        for column in training_columns_list:\n",
    "            fig, ax = plt.subplots(figsize=(10, 5), dpi=100)\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel(column)\n",
    "            plt.title('Time Series Generative Adversarial Network' + f' -{column}-')\n",
    "            plt.plot(df_real_unscaled[column], label='Actual')\n",
    "            plt.plot(df_pred_unscaled[column], label='Predicted')\n",
    "            plt.legend()\n",
    "            ax.yaxis.set_label_position('right')\n",
    "\n",
    "            if show_preds and column == 'Close':\n",
    "                plt.show()\n",
    "            fig.savefig(f\"./fig/plots_gan/{file_title}_plt_{column}_e{epoch}.png\")\n",
    "            plt.close(fig)\n",
    "\n",
    "    rmse_results = {}\n",
    "    for column in training_columns_list:\n",
    "        rmse = np.sqrt(\n",
    "            ((df_real_unscaled[column] - df_pred_unscaled[column]) ** 2).mean()\n",
    "        )\n",
    "        rmse_results[column] = rmse\n",
    "    return rmse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f0212",
   "metadata": {
    "id": "d4c51fa7"
   },
   "outputs": [],
   "source": [
    "generator = Generator(hidden_size=data_dimension * 2).to(device)\n",
    "discriminator = Discriminator(hidden_size=data_dimension * 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9ee09",
   "metadata": {
    "id": "95164560"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer_generator = optim.Adam(\n",
    "    generator.parameters(), lr=learning_rate, betas=optimizer_betas\n",
    ")\n",
    "optimizer_discriminator = optim.Adam(\n",
    "    discriminator.parameters(), lr=learning_rate, betas=optimizer_betas\n",
    ")\n",
    "\n",
    "real_label = 1.0\n",
    "fake_label = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed35852",
   "metadata": {
    "id": "0d56cf9b"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./models_gan/'):\n",
    "    os.makedirs('./models_gan/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8dc5f",
   "metadata": {
    "id": "d8b20864"
   },
   "outputs": [],
   "source": [
    "best_predictor = None\n",
    "min_close_rmse = math.inf\n",
    "\n",
    "evaluation_metrics = {'Generator_loss': [], 'Discriminator_loss': [], 'rmse_values': {}}\n",
    "for column in training_columns_list:\n",
    "    evaluation_metrics['rmse_values'][column] = []\n",
    "\n",
    "print('Training started !')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, sequence_batch in enumerate(train_dataloader):\n",
    "        discriminator.zero_grad()\n",
    "        real_sequence = sequence_batch.to(device)\n",
    "        batch_size = real_sequence.size(0)\n",
    "        real_labels = torch.full(\n",
    "            (batch_size,), real_label, dtype=torch.float, device=device\n",
    "        )\n",
    "        discriminator_output_real = discriminator(real_sequence).view(-1)\n",
    "        discriminator_error_real = criterion(discriminator_output_real, real_labels)\n",
    "        discriminator_error_real.backward()\n",
    "\n",
    "        generator_input_sequence = sequence_batch[:, :-1].to(device)\n",
    "        generated_values = generator(generator_input_sequence)\n",
    "        fake_labels = torch.full(\n",
    "            (batch_size,), fake_label, dtype=torch.float, device=device\n",
    "        )\n",
    "        generator_result_concat = torch.cat(\n",
    "            (generator_input_sequence, generated_values.detach()), 1\n",
    "        )\n",
    "        discriminator_output_fake = discriminator(generator_result_concat).view(-1)\n",
    "        discriminator_error_fake = criterion(discriminator_output_fake, fake_labels)\n",
    "        discriminator_error_fake.backward()\n",
    "        discriminator_error = discriminator_error_real + discriminator_error_fake\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "        generator.zero_grad()\n",
    "        real_labels = torch.full(\n",
    "            (batch_size,), real_label, dtype=torch.float, device=device\n",
    "        )\n",
    "        generator_result_concat_grad = torch.cat(\n",
    "            (generator_input_sequence, generated_values), 1\n",
    "        )\n",
    "        discriminator_output_fake = discriminator(generator_result_concat_grad).view(-1)\n",
    "        generator_error = criterion(discriminator_output_fake, real_labels)\n",
    "        generator_error.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "    if (epoch + 1) % evaluation_epoch_num == 0 or epoch + 1 == 1:\n",
    "        rmse_values = model_rmse(\n",
    "            generator,\n",
    "            validation_dataloader,\n",
    "            epoch=(epoch + 1),\n",
    "            plot_graph=True,\n",
    "            show_preds=False,\n",
    "        )\n",
    "        if rmse_values['Close'] < min_close_rmse:\n",
    "            min_close_rmse = rmse_values['Close']\n",
    "            best_predictor = epoch + 1\n",
    "\n",
    "        for column in training_columns_list:\n",
    "            evaluation_metrics['rmse_values'][column].append(rmse_values[column])\n",
    "\n",
    "        evaluation_metrics['Generator_loss'].append(generator_error.item())\n",
    "        evaluation_metrics['Discriminator_loss'].append(discriminator_error.item())\n",
    "\n",
    "        print(\n",
    "            '\\n[{}/{}]\\tDiscriminator Loss: {:.4f}\\tGenerator Loss: {:.4f}'.format(\n",
    "                epoch + 1,\n",
    "                num_epochs,\n",
    "                discriminator_error.item(),\n",
    "                generator_error.item(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for col_name, rmse in rmse_values.items():\n",
    "            print(f'{col_name} RMSE: {rmse:.4f}')\n",
    "        save_path = os.path.join(\"./models_gan/', 'model_epoch_{}.pt\".format(epoch + 1))\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch + 1,\n",
    "                'generator_model_state_dict': generator.state_dict(),\n",
    "                'discriminator_model_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_generator_state_dict': optimizer_generator.state_dict(),\n",
    "                'optimizer_discriminator_state_dict': optimizer_discriminator.state_dict(),\n",
    "                'discriminator_loss': discriminator_error,\n",
    "                'generator_loss': generator_error,\n",
    "            },\n",
    "            save_path,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f2fa5",
   "metadata": {},
   "source": [
    "# Dependencies<a id='dpdc'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas==1.3.5\n",
    "# !pip install numpy==1.21.4\n",
    "# !pip install matplotlib==3.5.1\n",
    "# !pip install mplfinance==0.12.8b6\n",
    "# !pip install yfinance==0.1.63\n",
    "# !pip install sklearn==0.23.2\n",
    "# !pip install mlxtend==0.19.0\n",
    "# !pip install statsmodels==0.11.1\n",
    "# !pip install pmdarima==1.8.0\n",
    "# !pip install prophet==1.0.1\n",
    "# !pip install tensorflow==2.7.0\n",
    "# !pip install torch==1.9.0"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
